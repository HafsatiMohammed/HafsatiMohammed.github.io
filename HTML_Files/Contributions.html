<!DOCTYPE html>
    <html>
      <head>
        <title> My PhD work </title>
        <meta charset="utf-8">
        <link rel="stylesheet" href="../style.css"/>
       </head> 
        <body>
              <nav>
             <ul>
              <li class="deroulant"><a href="#"> About my thesis </a>
                 <ul class="sous">
                   <li><a href="Context.html"> Context </a>
                   <li><a href="Obstacles.html"> Obstacle </a>
                   <li><a href="Solutions.html"> Solutions </a>
                   <li><a href="Contributions.html"> Contributions (sound source separation) </a>
                 </ul>
              </li>
              <li class="deroulant"><a href="#"> Examples</a>
                <ul class="sous">
                 <li><a href="Example1.html"> MSS example1</a>
                 <li><a href="Example2.html"> MSS example2 </a>
                  <li><a href="./Example_Navigation.html"> Navigation exemple </a>
                </ul>
              </li>
               <li class="deroulant"><a href="Contact.html"> Contact me</a>
              </li>
                               </li>
               <li class="deroulant"><a href="../index.html"> Home page</a>
              </li>
             </ul>
            </nav>
            
            
            
            
<div class= "content2">
 <p class= "PP1"> Contributions: </p>	 
  
 <p class="Para2"> In terms of multichannel sound source separation in the ambisonic domain, I contributed with the following works (check the scrolling menu to listen to some examples of sound source separation):	 
  
</p>	 
  
<ol>	 
  
 <li>In the microphone domain,	 
  
there is a multichannel sound separation approach proposed ten years ago and had never been used in the ambisonic domain yet. The approach is known as the multichannel sound source separation based on the local Gaussian model. I derived the equations of the model from the microphone domain to the ambisonic domain. It turned out that such a technique can be used in the ambisonic domain. I validated the approach with some numerical experiments. Referred to as FASST </li>	 
  
 <li> I proposed using the local Gaussian model approach and some side information coming from live recording spot microphones. I suggested a method to help the pre-processing of the side information and validate each block's efficiency through some numerical experiments. Referred to as SpotMic </li>	 
  
 <li> I proposed to use neural networks in the place of the spot microphones for musical content. I developed two different neural networks and compared the multichannel sound source separation performances through numerical experiments. Referred to as NN_EachForOne and NN_OneForAll </li>	</ol>
</div>
        </body>
    </html>
    
    
    
    
 
